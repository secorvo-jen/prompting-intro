---
theme: default
title: LLM Prompting Intro
info: Einstieg in den Dialog mit Large Language Models
author: Kai Jendrian
colorSchema: dark
drawings:
  persist: false
transition: slide-left
mdc: true
fonts:
  sans: Acme
  serif: Acme
  mono: JetBrains Mono
#  fallbacks: false
#  sans: Special Elite
#  serif: Special Elite
#  sans: Barriecito
#  serif: Barriecito
---
<div class="text-center">
<div style="font-size: 300%;">
Workshop <span style="color: yellow">"Besser wÃ¼nschen"</span>
</div>

<div class="h-12"></div>
<div class="flex flex-col gap-y-4">

<div style="font-size: 200%;">
<span style="color: grey;">TechniKA</span>
</div>

<i><span style="color: grey; font-size: 150%">Ein</span> <span style="color: orange; font-size: 150%">Einstieg</span> <span style="color: grey; font-size: 150%">in den konstruktiven Dialog mit LLMs</span></i>
</div>
<div class="h-12"></div>
<span style="color: red;">Kai Jendrian</span> (âœ‰ï¸ kai.jendrian@secorvo.de)
</div>

<!--

-->

---
layout: default
title: Alchemie
---
<img src="/assets/alchemy.jpg" style="display:block; margin:0 auto; width:50%; height:auto;" />
<div class="h-6"></div>
<v-clicks>
<div class="text-center" style="font-size: 110%;">
LLM-Prompting: Alchemie oder Wissenschaft?
</div>
</v-clicks>

---
layout: default
title: Fragen
---
<div class="text-center" style="font-size: 150%;">
Ein paar Fragen zum Warmwerden
</div>


<div class="text-center">
<v-clicks>

Wer von Euch nutzt KI-Chatbots?

Welche KI-Chatbots kennt Ihr?

WofÃ¼r nutzt Ihr KI-Chatbots?

Wie zufrieden seid Ihr mit den Ergebnissen?

</v-clicks>
</div>
---
layout: default
title: Grundlagen fÃ¼r einen effizienten Umgang mit Large Language Models (LLM)
---
<div class="text-center" style="font-size: 120%;">
Grundlagen fÃ¼r einen effizienten Umgang mit Large Language Models (LLM)</div>
<div class="h-6"></div>
<v-clicks>
<img src="/assets/sams_cover.jpg" style="display:block; margin:0 auto; width:55%; height:auto;" />
</v-clicks>
---
layout: default
title: Adam und Eva
---
<div class="text-center" style="font-size: 120%;">
Ein bisschen Theorie zum Einstieg - Adam und Eva der LLMs</div>
<div class="h-6"></div>
<div class="h-2"></div>
<img src="/assets/adam_eva.png" style="display:block; margin:0 auto; width:80%; height:auto;" />

---
layout: default
title: Fine Web
---
<img src="/assets/fine_web.png" style="display:block; margin:0 auto; width:100%; height:auto;" />
<div class="h-2"></div>
<div class="text-center">
<v-clicks>

Die Grundlage fÃ¼r Sprachmodelle ist ganz ganz viel Text.

(GroÃŸe) Sprachmodelle heiÃŸen auch (Large) Language Model oder (L)LM.

Der [Fine-Web Datensatz](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1) auf [Hugging Face](https://huggingface.co/) hat einen Umfang von ca. 44TB.

Eine Alternative dazu ist [Common Crawl](https://commoncrawl.org/).

</v-clicks>
</div>
---
layout: default
title: Tokenizing
---
<img src="/assets/tiktokenizer.png" style="display:block; margin:0 auto; width:50%; height:auto;" />
<div class="text-center">
<v-clicks>

LLMs arbeiten mit Tokens und nicht mit WÃ¶rtern. Texte werden in Token zerlegt.

GPT-4 hat ein Vokabular von ca. 100.000 Tokens.

Mehr Infos zu Tokens auf Youtube von [Chris Hay](https://youtu.be/NMoHHSWf1Mo). Ausprobieren kann man Tokenizing mit dem [TikTokenizer](https://tiktokenizer.vercel.app/).
</v-clicks>
</div>
<!--

-->
---
layout: default
title: Embedding

---
<img src="/assets/embedding_projector.png" style="display:block; margin:0 auto; width:50%; height:auto;" />
<div class="text-center">
<v-clicks>

Und eigentlich arbeiten LLMs auch nicht mit Token sondern Vektoren.

In GPT-3 ist jedes Token ein Vektor mit 12.288 Dimensionen. Spoiler: Schon 4 Dimensionen Ã¼berfordern uns.

Vektoren, die nahe beieinander liegen, haben Ã¤hnliche Bedeutungen.

Man kann mit Embeddings "rechnen": `"KÃ¶nig" - "Mann" + "Frau" â‰ˆ "KÃ¶nigin"`

Einen Eindruck von einem fertigen Embedding kann man sich mit einem [Embedding Projector](https://projector.tensorflow.org/) verschaffen.

Noch mehr Details zu den Interna von LLMs finden sich bei [3blue1brown](https://www.youtube.com/watch?v=wjZofJX0v4M)
</v-clicks>
</div>
---
layout: default
title: LLM Visualization
---
<img src="/assets/llm_inspect.png" style="display:block; margin:0 auto; width:80%; height:auto;" />

<div class="text-center">
<v-clicks>

Ein LLM ist letztendlich eine ziemlich komplizierte mathematische Formel um das nÃ¤chste Token vorherzusagen.

Vielleicht wagt Ihr einen [Blick unter die Haube](https://bbycroft.net/llm).

</v-clicks>
</div>
---
layout: default
title: Base Model
---
<img src="/assets/base_model_test.png" style="display:block; margin:0 auto; width:70%; height:auto;" />

<div class="text-center">
<v-clicks>

Ein Beispiel mit dem Base Model [Meta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B)

FÃ¤llt Euch hier schon etwas auf?

</v-clicks>
</div>


---
layout: default
title: Wo stehen wir jetzt?
---
<div class="text-center" style="font-size: 150%;">
Wo stehen wir jetzt?
</div>


<div class="text-center">
<v-clicks>

Texte sind in Token zerlegt und das LLM hat die Texte "gelernt".

Token sind in einem komplexen Vektorraum angeordnet.

Token, die im Embedding nahe beeinander liegen haben Ã„hnlichkeiten.

Wir haben ein sogenanntes "Base Model".

Ein Base Model ist in der Lage, Texte auf Basis des gelernten Wissens
fortzusetzen.
Damit ist das "Pre Training" abgeschlossen.

Im nÃ¤chsten Schritt muss das LLM lernen, sich wie ein Assistent zu verhalten.

Der nÃ¤chste Schritt heiÃŸt "Supervised Fine Tuning" (SFT).


</v-clicks>
</div>
---
layout: default
title: Wie baut man einen Chat GPT
---
<div class="h-12"></div>
<div class="text-center">
<div style="font-size: 300%;">
Wie kÃ¶nnte man ein Base Model trainieren, damit es sich wie ein hilfreicher Assistent oder eine hilfreiche Assistentin verhÃ¤lt und uns Fragen beantwortet?
</div>
</div>



---
layout: default
title: Viele Lehrer fÃ¼r ein LLM
---
<img src="/assets/viele_lehrer.png" style="display:block; margin:0 auto; width:80%; height:auto;" />

<div class="text-center">
<v-clicks>

In der Praxis werden die Base Models beim SFT mit ganz vielen Beispieldialogen trainiert.

</v-clicks>
</div>
---
layout: default
title: SFT TrainingsdatensÃ¤tze
---
<img src="/assets/open_assist.png" style="display:block; margin:0 auto; width:80%; height:auto;" />

<div class="text-center">
<v-clicks>

[OpenAssist](https://huggingface.co/datasets/OpenAssistant/oasst1/viewer) ist ein Beispiel fÃ¼r einen SFT-Trainingsdatensatz.

</v-clicks>
</div>
---
layout: default
title: Chatbot
---
<div class="text-center">
Und damit haben wir einen Chatbot:
</div>
<div class="h-4"></div>
<v-clicks>
<img src="/assets/chatbot.png" style="display:block; margin:0 auto; width:80%; height:auto;" />
</v-clicks>

---
layout: default
title: Chatbot
---

# Base Model vs. Chat Model

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

### Base Model:
```
Input: "ErklÃ¤re mir Schwerkraft"
```

```
Output: "ErklÃ¤re mir Schwerkraft in
einfachen Worten fÃ¼r Kinder.
Schwerkraft ist..."
```

â†’ VervollstÃ¤ndigt nur!

</v-clicks>
</div>
<div>
<v-clicks>

### Nach SFT (Chat Model):
```
User: "ErklÃ¤re mir Schwerkraft"
```

```
Assistant: "Gerne erklÃ¤re ich Dir
Schwerkraft! Schwerkraft ist eine
Kraft, die alle Objekte mit Masse..."
```

â†’ Versteht Anweisungen!

â†’ Arbeitet aber weiterhin als TextvervollstÃ¤ndigung!

</v-clicks>

</div>
</div>

---
layout: default
title: Prompting
---
<div class="text-center" style="font-size: 200%; color: red">
GENUG THEORIE</div>

<v-clicks>

<div>
<div class="h-6"></div>
<img src="/assets/gemini_prompt.png" style="display:block; margin:0 auto; width:55%; height:auto;" />
<div class="h-6"></div>
<div class="text-center" style="font-size: 200%; color: yellow">
Auf ans Prompten!</div>
</div>

</v-clicks>

---
title: Prompting - Die Kunst des WÃ¼nschens
---


<div class="text-center text-2xl mt-8">

# ğŸ¨ Prompting - Die Kunst des richtigen WÃ¼nschens

<v-clicks>

<div class="my-8">
<div class="grid grid-cols-2 gap-8">

<div class="border rounded p-6">
<div class="text-red-400 text-3xl mb-2">âŒ</div>
<div class="font-bold">Schlechter Prompt</div>
<div class="text-sm mt-2">"Schreib was Ã¼ber Hunde"</div>
</div>

<div class="border rounded p-6">
<div class="text-green-400 text-3xl mb-2">âœ…</div>
<div class="font-bold">Guter Prompt</div>
<div class="text-sm mt-2">"Schreibe einen kurzen Steckbrief Ã¼ber Golden Retriever fÃ¼r Kinder"</div>
</div>

</div>
</div>

## Im Folgenden: Ein paar **Prompting-Techniken** von einfach bis komplex

</v-clicks>

</div>
---
layout: default
---

<div class="text-center text-2xl mt-8">

# Was ist ein Prompt eigentlich?

<v-clicks>

- Dein Startschuss: Der Prompt ist alles, was Du der KI fÃ¼tterst, um sie zum Leben zu erwecken.

- Mehr als nur Googeln: Du suchst nicht nach Antworten, Du baust sie. Dein Prompt ist der Bauplan in Deinen eigenen Worten.

- Volle Kontrolle: Du gibst den Ton an. Du setzt den Kontext, verteilst die Aufgaben und entscheidest, was am Ende rauskommt.
</v-clicks>

</div>
---
layout: default
---

# ğŸ“ Level 1: Direkte Anweisungen (Zero-Shot)

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

## Was ist das?


Die **einfachste** Form des Promptings
- Klare, direkte Anweisung
- Keine Beispiele nÃ¶tig
- FÃ¼r Standard-Aufgaben

### Struktur:

```
"Anweisung" + "Optional: Details"
```

## ğŸ¨ Beispiele:

```
"Ãœbersetze ins Englische: Guten Morgen"

"ErklÃ¤re Photosynthese in 2 SÃ¤tzen"

"Schreibe ein Haiku Ã¼ber den Winter"
```

</v-clicks>

</div>

<div>

<v-clicks>

## ğŸ’¡ Tipps fÃ¼r gute Anweisungen


### âœ… DO:
- Sei **spezifisch**: "Schreibe 3 SÃ¤tze" statt "Schreib was"
- Nenne **Format**: "als Liste", "als Tabelle"
- Definiere **Zielgruppe**: "fÃ¼r Kinder", "fÃ¼r Experten"

### âŒ DON'T:
- Zu vage: "ErzÃ¤hl mir was Ã¼ber Tiere"
- WidersprÃ¼chlich: "Kurz, aber sehr detailliert"
- Mehrdeutig: "Mach das besser"

### ğŸ¯ Ãœbung:
**Verbessere:** "Schreib Ã¼ber Computer"

â†’ **Besser:** "ErklÃ¤re einem 10-JÃ¤hrigen in 3 SÃ¤tzen, wie ein Computer funktioniert"

</v-clicks>

</div>

</div>

---
layout: default
title: Prompting Level 2 - One-Shot Learning
---

# ğŸ¯ Level 2: One-Shot Learning (Ein Beispiel)

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

## Was ist das?

Du gibst **ein Beispiel** fÃ¼r das gewÃ¼nschte Format

### Warum?
- LLM versteht **Muster** aus Beispielen
- Besser als lange ErklÃ¤rungen
- FÃ¼r spezielle Formate/Stile

### Struktur:
```
Beispiel:
[Input] â†’ [Output]

Jetzt Du:
[Neuer Input] â†’
```

</v-clicks>

</div>

<div>

<v-clicks>

## ğŸ¨ Beispiele

### Stimmungstest:
```
Beispiel:
Satz: "Ich liebe diesen Film!"
Stimmung: Positiv

Jetzt Du:
Satz: "Das war langweilig."
Stimmung:
```

### Textstil:
```
Beispiel:
Normal: "Der Hund lÃ¤uft schnell."
Poetisch: "BehÃ¤nde eilt der Vierbeiner dahin."

Jetzt Du:
Normal: "Es regnet stark."
Poetisch:
```

</v-clicks>

</div>
</div>

---
layout: default
title: Prompting Level 3 - Few-Shot Learning
---

# ğŸ“ Level 3: Few-Shot Learning (Mehrere Beispiele)

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

## Was ist das?

Gib **2-5 Beispiele** fÃ¼r besseres VerstÃ¤ndnis

### Warum mehrere Beispiele?
- LLM erkennt **konsistente Muster**
- Reduziert MissverstÃ¤ndnisse
- FÃ¼r komplexe Aufgaben

### Faustregel:
- **1 Beispiel**: Einfache Formate
- **2-3 Beispiele**: Standard-Aufgaben
- **4-5 Beispiele**: Komplexe Muster

</v-clicks>

</div>

<div>

<v-clicks>

## ğŸ“Š Beispiel: Klassifikation

```
Klassifiziere die Programmiersprache:

1. "print('Hallo')" â†’ Python
2. "console.log('Hallo')" â†’ JavaScript
3. "System.out.println('Hallo')" â†’ Java
4. "echo 'Hallo'" â†’ Bash

Jetzt Du:
5. "puts 'Hallo'" â†’
```

**Vorteil:** LLM sieht verschiedene Muster!

### ğŸ§ª Experiment:
**Teste daheim mit 1 vs. 3 Beispielen:**
- Welche Genauigkeit?
- Welche Konsistenz?

</v-clicks>

</div>

</div>

---layout: center
layout: default
title: Prompting Level 4 - Chain-of-Thought (CoT)
---

# ğŸ§  Level 4: Chain-of-Thought (Gedankenkette)

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

## Was ist das?

LLM soll **Denkschritte** zeigen

### SchlÃ¼ssel-Phrase:
```
"Denke Schritt fÃ¼r Schritt"
"ErklÃ¤re Deinen Gedankengang"
```

### Warum wirkt das?
- LLM "Ã¼berlegt" lÃ¤nger
- Fehler werden sichtbar
- Bessere Ergebnisse bei Logik/Mathe

### Wann verwenden?
- âœ… Mathematik, Logik-RÃ¤tsel
- âœ… Komplexe Entscheidungen
- âŒ Einfache Fakten

</v-clicks>

</div>

<div>

<v-clicks>

## ğŸ”¢ Beispiele

### Ohne CoT:
```
"Was ist 23 * 47?"
â†’ "1081" (oft falsch!)
```

### Mit CoT:
```
"Was ist 23 * 47? Denke Schritt fÃ¼r Schritt."

â†’ "Lass mich das ausrechnen:
1. 23 * 40 = 920
2. 23 * 7 = 161
3. 920 + 161 = 1081

Antwort: 1081"
```

### ğŸ§© Logik-Beispiel:
```
"Wenn alle A gleich B sind, und alle B
gleich C sind, was folgt daraus?
Denke Schritt fÃ¼r Schritt."
```

</v-clicks>

</div>

</div>

---
layout: default
title: Prompting Level 5 - Rollen-Prompting
---

# ğŸ­ Level 5: Rollen-Prompting (Persona)

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

## Was ist das?

Weise dem LLM eine **Rolle/IdentitÃ¤t** zu

### Struktur:
```
"Du bist [Rolle]. [Aufgabe]"
"Als [Experte], [mach etwas]"
```

### Warum?
- Ã„ndert **Schreibstil**
- Aktiviert **Fach-Wissen**
- Passt **KomplexitÃ¤t** an

### Beliebte Rollen:
- Experte (Lehrer, Programmierer, ...)
- Zielgruppe (Kind, AnfÃ¤nger, ...)
- Stil (Poet, Journalist, ...)

</v-clicks>

</div>

<div>

<v-clicks>

## ğŸ¨ Beispiele

### Experten-Rolle:
```
"Du bist ein Physik-Professor. ErklÃ¤re
QuantenverschrÃ¤nkung fÃ¼r Studenten."
```

### Zielgruppen-Anpassung:
```
"ErklÃ¤re Photosynthese als wÃ¤rst Du
ein begeisterter Biologie-Lehrer fÃ¼r
8-JÃ¤hrige."
```

### Stil-Ã„nderung:
```
"Du bist Shakespeare. Schreibe einen
Tweet Ã¼ber Programmieren."
```

### ğŸ’¡ Kombiniere mit anderen Techniken:
```
"Du bist Mathe-Lehrerin. LÃ¶se 47*23
Schritt fÃ¼r Schritt fÃ¼r einen SchÃ¼ler."
```

</v-clicks>

</div>

</div>

---
layout: default
title: Prompting Level 6 - System-Prompts
---

# âš™ï¸ Level 6: System-Prompts (Globale Anweisungen)

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

## Was ist das?

**Grund-Einstellungen** fÃ¼r das gesamte GesprÃ¤ch

### Unterschied:
```
System-Prompt: Grundverhalten
User-Prompt: Spezifische Aufgabe
```

### System-Prompt definiert:
- ğŸ­ Basis-Rolle
- ğŸ“ Output-Regeln
- ğŸš« EinschrÃ¤nkungen
- ğŸ¨ Stil-Vorgaben

### In APIs:
```python
{
  "system": "Du bist hilfsbereit...",
  "user": "ErklÃ¤re Python"
}
```

</v-clicks>

</div>

<div>

<v-clicks>

## ğŸ“ Beispiele

### Standard-System-Prompt:
```
"Du bist ein hilfreicher, ehrlicher und
harmloser KI-Assistent."
```

### Spezialisierter System-Prompt:
```
"Du bist ein Python-Tutor fÃ¼r AnfÃ¤nger.
- ErklÃ¤re alles einfach
- Gib immer Beispiel-Code
- Verwende Emojis
- Antworte auf Deutsch
- Nie lÃ¤nger als 5 SÃ¤tze"
```

### EinschrÃ¤nkungen:
```
"Du bist Mathe-Helfer.
- Gib NIE direkt die LÃ¶sung
- Stelle RÃ¼ckfragen
- Gib nur Hinweise"
```
</v-clicks>

</div>

</div>

---
layout: default
title: Prompting Level 7 - Kontext-Management
---

# ğŸ“š Level 7: Kontext-Management (RAG-Prinzip)

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

## Was ist Kontext?

Alle **Informationen**, die das LLM sieht:
- Bisherige Nachrichten
- EingefÃ¼gte Dokumente
- System-Anweisungen

### Kontext-Fenster:
```
GPT-4: ~128k Token (~96k WÃ¶rter)
Claude: ~200k Token (~150k WÃ¶rter)
Gemini: ~1M Token (~750k WÃ¶rter)
```

### Wichtig:
- Kontext = Kosten ğŸ’°
- Kontext = Geschwindigkeit
- Mehr Kontext nicht immer bessere Antwort

</v-clicks>

</div>

<div>

<v-clicks>

## ğŸ¯ Kontext richtig nutzen

### RAG (Retrieval Augmented Generation):
```
1. Finde relevante Infos
2. FÃ¼ge sie dem Prompt hinzu
3. Stelle die Frage

"Hier ist der Artikel: [TEXT]

Beantworte basierend auf dem
Artikel: Wann wurde...?"
```

### âš ï¸ Context Engineering:
```
âœ… Relevante Infos zuerst
âœ… Strukturiere mit Markdown
âœ… Klare Trennungen
âŒ Zu viel unwichtiger Text
âŒ Redundante Informationen
```

### ğŸ“– Vertiefung:
ğŸ”— [Context Engineering Guide](https://www.promptingguide.ai/guides/context-engineering-guide)

</v-clicks>

</div>

</div>

---
layout: default
title: Kontext-Strategie - Best Practices
---

# ğŸ¯ Kontext-Strategie: Best Practices

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

## Guter Kontext-Aufbau

### Struktur-Template:
```markdown
## Kontext:
[Relevante Hintergrund-Infos]

## Daten:
[Spezifische Daten/Dokumente]

## Aufgabe:
[Was soll gemacht werden?]

## Format:
[Wie soll das Ergebnis aussehen?]
```

### Warum strukturieren?
- LLM findet Infos schneller
- Weniger Verwirrung
- Bessere Ergebnisse

</v-clicks>

</div>

<div>

<v-clicks>

## ğŸ“Š Beispiel: Dokument-Analyse

### âŒ Schlechter Prompt:
```markdown
Hier ist ein Text [5000 WÃ¶rter]
Was ist wichtig?
```

### âœ… Guter Prompt:
```markdown
## Dokument:
[Text]

## Aufgabe:
Extrahiere die 3 Hauptaussagen Ã¼ber
Klimawandel.

## Format:
- Aussage 1: [...]
- Aussage 2: [...]
- Aussage 3: [...]

## Kontext:
Das Dokument ist fÃ¼r eine SchulprÃ¤sentation.
```
</v-clicks>

</div>

</div>

---
layout: default
title: Prompting Level 8 - Meta-Prompting
---

# ğŸ”„ Level 8: Meta-Prompting (Selbst-Verbesserung)

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

<v-clicks>

## Was ist das?

LLM **verbessert seine eigenen Antworten**

### Techniken:
1. **Self-Critique**: "PrÃ¼fe Deine Antwort"
2. **Iteration**: "Verbessere Deine Antwort"
3. **Reflexion**: "Was kÃ¶nnte falsch sein?"

### Beispiel-Flow:
```
User: [Frage]
â†’ LLM: [Antwort]
â†’ User: "PrÃ¼fe auf Fehler"
â†’ LLM: [Korrigierte Antwort]
```

</v-clicks>

</div>

<div>

<v-clicks>

## ğŸ§ª Praktische Beispiele

### Self-Critique:
```
"ErklÃ¤re Quantencomputer.

PrÃ¼fe jetzt Deine ErklÃ¤rung:
1. Ist sie korrekt?
2. Ist sie verstÃ¤ndlich?
3. Fehlt etwas Wichtiges?
Korrigiere falls nÃ¶tig."
```

### Iterative Verbesserung:
```
"Schreibe einen Werbetext fÃ¼r
eine App.

Jetzt:
1. Bewerte den Text (1-10)
2. Identifiziere SchwÃ¤chen
3. Schreibe eine bessere Version"
```

### ğŸ¯ Tipp: Kombiniere mit CoT!

</v-clicks>

</div>

</div>

---
layout: center
title: Zusammenfassung Prompting-Techniken
---

# ğŸ“‹ Prompting-Techniken: Zusammenfassung

<div class="text-sm">

| Level | Technik | Wann nutzen? | KomplexitÃ¤t |
|-------|---------|--------------|-------------|
| 1ï¸âƒ£ | **Zero-Shot** | Standard-Aufgaben, klare Anweisungen | â­ |
| 2ï¸âƒ£ | **One-Shot** | Spezielle Formate zeigen | â­â­ |
| 3ï¸âƒ£ | **Few-Shot** | Konsistente Muster vermitteln | â­â­ |
| 4ï¸âƒ£ | **Chain-of-Thought** | Mathe, Logik, komplexe Probleme | â­â­â­ |
| 5ï¸âƒ£ | **Rollen-Prompting** | Stil/Expertise anpassen | â­â­ |
| 6ï¸âƒ£ | **System-Prompts** | Grundverhalten festlegen | â­â­â­ |
| 7ï¸âƒ£ | **Kontext-Management** | Mit Dokumenten/Daten arbeiten | â­â­â­â­ |
| 8ï¸âƒ£ | **Meta-Prompting** | HÃ¶chste QualitÃ¤t bei komplexen Aufgaben | â­â­â­â­â­ |

</div>

<v-click>

<div class="text-center mt-8 text-xl">
ğŸ’¡ **Kombination** verschiedener Techniken = Beste Ergebnisse!
</div>

</v-click>

---
layout: center
title: LLMs als Lernpartner
---

# ğŸ¤– LLMs als Lernpartner: Best Practices

<div class="text-sm">

| # | Prinzip | Wie nutzen? | Achtung! |
|---|---------|-------------|----------|
| 1ï¸âƒ£ | **Der Assistent** | FÃ¼r Ideen, Gliederungen & EntwÃ¼rfe | âš ï¸ Macht Fehler & halluziniert |
| 2ï¸âƒ£ | **Output-PrÃ¼fung** | Fakten checken & Quellen suchen | ğŸ” Wirkt glaubwÃ¼rdig, oft falsch |
| 3ï¸âƒ£ | **Denkpartner** | "ErklÃ¤re mir..." statt "LÃ¶se fÃ¼r mich..." | ğŸ§  Copy & Paste verhindert Lernen |
| 4ï¸âƒ£ | **Datenschutz** | Anonyme Aufgabenstellungen nutzen | ğŸ›¡ï¸ Keine Namen oder privaten Daten! |
| 5ï¸âƒ£ | **Schreibstil** | Feedback zu eigenen Texten einholen | âœï¸ Behalte Deine eigene Stimme |

</div>

<v-click>

<div class="text-center mt-8 text-xl">
ğŸ’¡ **Merke:** Die KI ist der Co-Pilot, Du bist der Pilot!
</div>

</v-click>
---
layout: default
title: Bonus - LLM Hacking
---

# ğŸ”“ Bonus: LLM Hacking & "Prompt Injection"


<div class="grid grid-cols-2 gap-6 mt-4">

<div>
<img src="/assets/gandalf.png" class="rounded-lg shadow-lg border border-gray-600 opacity-90" alt="Gandalf Interface" />
</div>

<div>
<div class="ml-8">

### Was ist "Prompt Injection"?
Der Versuch, die Sicherheitsregeln ("System Prompts") einer KI durch geschickte Eingaben zu umgehen.

- **Ziel:** Die KI dazu bringen, verbotene Dinge zu tun (z.B. PasswÃ¶rter verraten).
- **Warum relevant?** Zeigt SicherheitslÃ¼cken aktueller Modelle auf.

<div class="mt-8 p-4 bg-red-900/20 border border-red-500/30 rounded-lg">
  <h3 class="text-xl text-white m-0">ğŸ§™â€â™‚ï¸ Challenge: Gandalf</h3>
  <p class="text-sm mt-2 mb-2 opacity-80">
    Trainiere Deine Skills ("Red Teaming"). Deine Mission: Entlocke Gandalf das Passwort!
  </p>
  <a href="https://gandalf.lakera.ai/gandalf" class="font-mono text-blue-400 hover:text-blue-300">
    ğŸ‘‰ gandalf.lakera.ai/gandalf
  </a>
</div>

</div>
</div>
</div>
---
layout: default
title: WeiterfÃ¼hrende Quellen
---

# ğŸ“š Futter fÃ¼rs Gehirn: WeiterfÃ¼hrende Quellen

<div class="grid grid-cols-2 gap-6 mt-4">

<div>

### ğŸ¥ Verstehen & Staunen

- **[Die Maus: Wie schreibt KI?](https://kinder.wdr.de/tv/die-sendung-mit-der-maus/av/wie-schreibt-eine-ki-texte-100.html)**
  <br><span class="text-sm opacity-70 italic">"ErklÃ¤rt es oft besser als Informatik-Professoren. Kein Witz."</span>

- **[3blue1brown (Transformers)](https://www.youtube.com/watch?v=wjZofJX0v4M)**
  <br><span class="text-sm opacity-70 italic">"FÃ¼r alle, die Mathe nur mÃ¶gen, wenn es schÃ¶n tanzt. Visuell brillant."</span>

- **[Andrej Karpathy: Deep Dive](https://www.youtube.com/watch?v=7xTGNNLPyMI&t=18s)**
  <br><span class="text-sm opacity-70 italic">"Der Endgegner. Wirkt wie ein Semesterstudium in einem Video. Nur fÃ¼r Mutige."</span>

- **[Prompt Engineering Guide](https://www.promptingguide.ai/)**
  <br><span class="text-sm opacity-70 italic">"Die Bibel. Trocken wie KnÃ¤ckebrot, aber extrem nahrhaft."</span>

</div>
<div>

### ğŸ› ï¸ Ausprobieren & Meistern

- **[LM Arena (Chatbot Arena)](https://lmarena.ai/)**
  <br><span class="text-sm opacity-70 italic">"Battle Royale der KIs. Du chattest mit zwei anonymen Modellen und kÃ¼rst den Sieger."</span>

- **[Teachable Machine](https://teachablemachine.withgoogle.com/)**
  <br><span class="text-sm opacity-70 italic">"Der 'Aha-Effekt'. Trainiere Deine eigene KI mit der Webcam. Ohne Code."</span>

- **[Hugging Face Playground](https://huggingface.co/playground)**
  <br><span class="text-sm opacity-70 italic">"Der Abenteuerspielplatz fÃ¼r Open-Source Modelle."</span>

- **[Soekia Chat](https://www.soekia.ch/gpt.html)**
  <br><span class="text-sm opacity-70 italic">"Datenschutzfreundlich. Perfekt, um nicht gleich seine Seele zu verkaufen."</span>

- **[Anthropic](https://docs.claude.com/) & [OpenAI Guides](https://academy.openai.com/)**
  <br><span class="text-sm opacity-70 italic">"Kochrezepte vom Chefkoch persÃ¶nlich. RTFM lohnt sich hier."</span>

</div>
</div>
---
